{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/CCPiOIIC/blob/main/ML/%D0%90%D1%80%D0%B0%D0%B1%D0%BE%D0%B2%D0%9C%D0%9A_%D0%A0%D0%B5%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F_%D1%8F%D0%B7%D1%8B%D0%BA%D0%BE%D0%B2%D0%BE%D0%B9_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmZiFVcabyX1"
      },
      "source": [
        "#Генерация текста\n",
        "\n",
        "В этом уроке мы познакомимся с генерацией текста на практике, а именно -- реализуем языковую модель (то есть обучим модель генерировать текст заданном стиле). В качестве модели возьмём Char-RNN, то есть работать будем на уровне отдельных символов (букв).\n",
        "\n",
        "В качестве обучающей выборки (корпуса) возьмём текст произведения Шекспира.\n",
        "В результате наша обученная языковая модель должна генерировать текст в таком же стиле."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu9Fy3R7b5cx"
      },
      "source": [
        "### Используем TensorFlow 2.0\n",
        "\n",
        "На момент подготовки этих материалов в Google Colab по умолчанию используется версия TensorFlow 1.X\n",
        "\n",
        "Переключаемся на версию 2.0 (работает только в Colab)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMnq-IQdUYef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e582955d-289d-41fc-e885-03d787b2bbd0"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zI3nDdteAqz"
      },
      "source": [
        "### Загрузка библиотек\n",
        "TensorFlow должен иметь как минимум версию 2.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ew7HTbPpCJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "535be4a8-bfde-4631-d31a-96ad247fc428"
      },
      "source": [
        "import codecs\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mxS1MXerOQo"
      },
      "source": [
        "### Загрузка датасета\n",
        "\n",
        "Скачиваем файл с текстом (`shakespeare.txt`) и загружаем его содержимое в переменную `text`.\n",
        "\n",
        "Посмотрим, как выглядит текст, распечатав его фрагмент. Видно, что тексту свойственна некоторая стилистика пьесы."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D1IlHYLAv5l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "942665b9-31ce-4684-e71f-f014026d5326"
      },
      "source": [
        "data_fpath = tf.keras.utils.get_file(\n",
        "    'shakespeare.txt',\n",
        "    'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "\n",
        "text = codecs.open(data_fpath, 'r', encoding='utf8').read()\n",
        "print(text[:250])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1us/step\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRjGXLEjrJY3"
      },
      "source": [
        "### Конвертация символов в индексы\n",
        "\n",
        "Как и раньше (как мы делали в случае классификации текстов), нам будет удобно работать с некоторым словарём и индексами слов в данном словаре. Только сейчас вместо слов мы будем испоьзовать символы (буквы итд).\n",
        "\n",
        "Чтобы получить словарь `vocab` достаточно применить оператор `set` к нашему тексту (то есть конвертировать последовательность всех символов в множество = удалить все повторы). `VOCAB_SIZE` -- количество элементов в словаре.\n",
        "\n",
        "Затем, как и раньше, создаём отображения символа в индекс и наоборот (`char2idx`, `idx2char`)\n",
        "\n",
        "Теперь конвертируем наш текст в последовательность индексов с помощью `char2idx`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3O9nwfSA6mM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52b088fa-9c8c-4831-fb77-c72053047099"
      },
      "source": [
        "vocab = sorted(set(text))\n",
        "VOCAB_SIZE = len(vocab)\n",
        "\n",
        "print('Vocab: {}'.format(vocab))\n",
        "print('{} unique characters'.format(VOCAB_SIZE))\n",
        "\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])\n",
        "\n",
        "print('Example of the encoded text: {}'.format(text_as_int[:13]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab: ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "65 unique characters\n",
            "Example of the encoded text: [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctn8Gs37rDZo"
      },
      "source": [
        "### Подготовка датасета\n",
        "\n",
        "Во время инференса наш генератор  будет работать следующим образом: сначала мы подаём входной символ или входную последовательность (зерно), получаем первый выходной символ, а затем подаём его как входной символ и так далее (генерируем по одному символу за раз).\n",
        "\n",
        "А во время обучения будем обучать модель работать сразу с целой последовательностью. Например, обученная модель должна по входу `[F, i, r, s, ...]` выдавать `[i, r, s, t, ...]`. То есть ту же последовательность, но сдвинутую на 1 элемент. В данном случае это будет эквивалентно Many-to-Many Sync (только во время обучения).\n",
        "\n",
        "Таким образом, зафиксируем длину рабочей цепочки `SEQ_LEN` (на которой будем обучаться), разрежем весь текст на цепочки длины `SEQ_LEN+1` (остаток отбросим), и из каждой такой цепочки длины `SEQ_LEN+1` получим пару цепочек длины `SEQ_LEN`, сдвинутых на 1 элемент: входная цепочка (без последнего элемента) и целевая (истинная) цепочка (начиная со второго элемента).\n",
        "\n",
        "Кроме того, зафиксируем размер батча для обучения и отбросим цепочки в конце, которые не могут наполнить полный батч (чтоб кол-во обучающих цепочек было кратно размеру батча).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lL74PG-Cbn7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b342a10-dba8-4f7d-c8b6-1246525bc4d0"
      },
      "source": [
        "SEQ_LEN = 1000\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "input_seqs = []\n",
        "target_seqs = []\n",
        "\n",
        "num_seqs = len(text_as_int) // (SEQ_LEN+1)\n",
        "for i in range(num_seqs):\n",
        "    seq = text_as_int[i:i+SEQ_LEN+1]\n",
        "    input_seqs.append(np.array(seq[:-1]))\n",
        "    target_seqs.append(np.array(seq[1:]))\n",
        "\n",
        "input_seqs = np.array(input_seqs)\n",
        "target_seqs = np.array(target_seqs)\n",
        "\n",
        "input_seqs = input_seqs[:(len(input_seqs)//BATCH_SIZE)*BATCH_SIZE]\n",
        "target_seqs = target_seqs[:(len(input_seqs)//BATCH_SIZE)*BATCH_SIZE]\n",
        "\n",
        "print('Input: {} ...'.format([idx2char[i] for i in input_seqs[0][:15]]))\n",
        "print('Target: {} ...'.format([idx2char[i] for i in target_seqs[0][:15]]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: ['F', 'i', 'r', 's', 't', ' ', 'C', 'i', 't', 'i', 'z', 'e', 'n', ':', '\\n'] ...\n",
            "Target: ['i', 'r', 's', 't', ' ', 'C', 'i', 't', 'i', 'z', 'e', 'n', ':', '\\n', 'B'] ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jF-Bv_-CmQQp"
      },
      "source": [
        "### Функция построения модели\n",
        "\n",
        "Здесь мы создадим нашу модель с помощью `tf.keras.Sequential`.\n",
        "\n",
        "Модель будет состоять из трёх слоёв:\n",
        "* Embedding слой для отображения индексов букв в их вектрное представление\n",
        "* Рекуррентный слой GRU\n",
        "* Полносвязный слой, предсказывающий распределение по различным буквам (например, можно потом навесить Argmax, чтобы понять, какую именно букву предсказывает слой)\n",
        "\n",
        "На выходе нам нужно получить последовательность такой же длины, что и входная,то есть чтоб GRU слой возвращал всю цепочку скрытых векторов, а не только последний. Для этого в параметрах GRU слоя зададим `return_sequences=True`.\n",
        "\n",
        "Во время обучения будем просить модель предсказать входную цепочку, сдвинутую на 1 элемент. A во время инференса -- будем постепенно подавать символ за символом (то есть при каждом инференсе модель будет делать отображение \"один в один\"). Теоретически можно было бы и во время обучения делать так же -- постепенно генерировать выход (символ за символом), подавая результат предыдущей итерации (предыдущий символ) на вход в текущей итерации. Но сеть будет обучаться лучше, если мы будем \"заставлять\" её использовать \"правильные\" входы, а не то, что она сама нагенерировала.\n",
        "\n",
        "Чтобы во время инференса при различных запусках модели она помнила своё предыдущее состояние (иначе не получится использовать рекуррентность, ведь мы будем подавать последовательно последовательности из одного элемента), мы укажем флаг `stateful=True`\n",
        "\n",
        "Кроме того, если модель имеет флаг `stateful=True`, ей нужно заранее знать размер батча (зададим через `batch_input_shape`). А так как у нас размер батча будет разный (для обучения >1, для инференса =1), нам понадобится создать модель два раза. Чтобы не дублировать код создания модели, обернём её создание в функцию `build_model`, которая принимает размер батча в качестве аргумента."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeyPx8G7Dj76"
      },
      "source": [
        "def build_model(batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(VOCAB_SIZE, 256, input_length=None),  # Используем input_length вместо batch_input_shape\n",
        "        tf.keras.layers.GRU(256, return_sequences=True, stateful=True),\n",
        "        tf.keras.layers.Dense(VOCAB_SIZE),\n",
        "    ])\n",
        "    model.build(input_shape=(batch_size, None))  # Указываем input_shape при вызове build\n",
        "    return model\n",
        "\n",
        "model = build_model(BATCH_SIZE)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meVPzY2TmKVq"
      },
      "source": [
        "### Обучение модели\n",
        "\n",
        "На выходе модели у нас полносвязный слой без функции активации, то есть это просто логиты. По ним нам надо по сути сделать классификацию (номер класса = номер предсказанного символа). Для логитов и целевых (истинных) значений, представленных индексами, надо использовать лосс `SparseCategoricalCrossentropy(from_logits=True)`\n",
        "\n",
        "Далее обучаем модель стандартным способом на наборах `(input_seqs, target_seqs)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYJbm9T0FVS2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8a439dc-7e76-40a6-8239-024b1b3dcc86"
      },
      "source": [
        "EPOCHS = 100\n",
        "\n",
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(optimizer='adam', loss=loss)\n",
        "\n",
        "history = model.fit(input_seqs,\n",
        "    target_seqs,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 3.6071\n",
            "Epoch 2/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 2.3486\n",
            "Epoch 3/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 1.9888\n",
            "Epoch 4/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 1.6831\n",
            "Epoch 5/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 1.3645\n",
            "Epoch 6/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 1.0243\n",
            "Epoch 7/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.7055\n",
            "Epoch 8/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.4543\n",
            "Epoch 9/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.2836\n",
            "Epoch 10/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.1859\n",
            "Epoch 11/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.1248\n",
            "Epoch 12/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0909\n",
            "Epoch 13/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0740\n",
            "Epoch 14/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0608\n",
            "Epoch 15/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0543\n",
            "Epoch 16/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0482\n",
            "Epoch 17/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0442\n",
            "Epoch 18/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0401\n",
            "Epoch 19/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0374\n",
            "Epoch 20/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0337\n",
            "Epoch 21/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0314\n",
            "Epoch 22/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0293\n",
            "Epoch 23/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0272\n",
            "Epoch 24/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0291\n",
            "Epoch 25/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0262\n",
            "Epoch 26/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0240\n",
            "Epoch 27/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0222\n",
            "Epoch 28/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0212\n",
            "Epoch 29/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0201\n",
            "Epoch 30/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0194\n",
            "Epoch 31/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0187\n",
            "Epoch 32/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0183\n",
            "Epoch 33/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0176\n",
            "Epoch 34/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0176\n",
            "Epoch 35/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0174\n",
            "Epoch 36/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0164\n",
            "Epoch 37/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0167\n",
            "Epoch 38/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0163\n",
            "Epoch 39/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0157\n",
            "Epoch 40/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0159\n",
            "Epoch 41/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0151\n",
            "Epoch 42/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0154\n",
            "Epoch 43/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0146\n",
            "Epoch 44/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0146\n",
            "Epoch 45/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0146\n",
            "Epoch 46/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0141\n",
            "Epoch 47/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0143\n",
            "Epoch 48/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0138\n",
            "Epoch 49/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0140\n",
            "Epoch 50/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0134\n",
            "Epoch 51/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0134\n",
            "Epoch 52/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0134\n",
            "Epoch 53/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0135\n",
            "Epoch 54/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0131\n",
            "Epoch 55/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0130\n",
            "Epoch 56/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0127\n",
            "Epoch 57/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0129\n",
            "Epoch 58/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0126\n",
            "Epoch 59/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0124\n",
            "Epoch 60/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0122\n",
            "Epoch 61/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0127\n",
            "Epoch 62/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0123\n",
            "Epoch 63/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0122\n",
            "Epoch 64/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0118\n",
            "Epoch 65/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0119\n",
            "Epoch 66/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0119\n",
            "Epoch 67/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0236\n",
            "Epoch 68/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0153\n",
            "Epoch 69/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0130\n",
            "Epoch 70/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0124\n",
            "Epoch 71/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0119\n",
            "Epoch 72/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0118\n",
            "Epoch 73/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0120\n",
            "Epoch 74/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0116\n",
            "Epoch 75/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0115\n",
            "Epoch 76/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0114\n",
            "Epoch 77/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0114\n",
            "Epoch 78/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0113\n",
            "Epoch 79/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0109\n",
            "Epoch 80/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0110\n",
            "Epoch 81/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0114\n",
            "Epoch 82/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0108\n",
            "Epoch 83/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0110\n",
            "Epoch 84/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0106\n",
            "Epoch 85/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0107\n",
            "Epoch 86/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0107\n",
            "Epoch 87/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0109\n",
            "Epoch 88/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0106\n",
            "Epoch 89/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0104\n",
            "Epoch 90/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0104\n",
            "Epoch 91/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0103\n",
            "Epoch 92/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.0104\n",
            "Epoch 93/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0103\n",
            "Epoch 94/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0103\n",
            "Epoch 95/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0102\n",
            "Epoch 96/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0102\n",
            "Epoch 97/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0100\n",
            "Epoch 98/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0100\n",
            "Epoch 99/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0101\n",
            "Epoch 100/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBNpBNC9qKvf"
      },
      "source": [
        "### Создание модели для инференса\n",
        "\n",
        "После обучения модели нам надо создать такую же модель, но с размером батча =1, которую позже будем использовать для инференса (`model_inf`). Воспользуемся для этого функцией `build_model`, а затем скопируем обученные веса из `model` в новую модель `model_inf`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxn--qQbPbAv"
      },
      "source": [
        "model_inf = build_model(1)\n",
        "\n",
        "for i in range(len(model_inf.layers)):\n",
        "    for j in range(len(model_inf.layers[i].weights)):\n",
        "        model_inf.layers[i].weights[j].assign(model.layers[i].weights[j])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AglUZjgq6NO"
      },
      "source": [
        "### Функция генерации текста\n",
        "\n",
        "Создадим функцию, генерирующую текст по данной модели (`model`), входной цепочке (зерну `seed`) и желаемому количеству сгенерированных символов (`out_len`).\n",
        "\n",
        "Внутри функции сначчала вызовем `model.reset_states()` для обнуления предыдущей истории состояния.\n",
        "\n",
        "Затем конвертируем входной текст `seed` (символы в индексы) и прогоним его через нашу модель. Нас интересует результат, соответствующих только последнему выходу (символу).\n",
        "\n",
        "Как получить сам символ по предсказанию модели? Один из простейших способов -- просто взять argmax от предсказанных логитов (взять символ с наибольшей вероятностью). Однако, в таком случае выход часто будет слишком предсказуемым и иногда цепочка будет застрявать в цикличности (повторяться).\n",
        "\n",
        "Для того, чтобы сделать предсказание менее предсказуемым, воспользуемся реальным распределенем и будем \"сэмплировать\" из него (то есть выбирать символ случайным образом в соответствии с его вероятностью). Сделать это можно с помощью функции `tf.random.categorical`. На вход в `categorical` мы подаём всю матрицу `pred` (у которой первое измерение это длина цепочки, а второе - распределение по классам), а на выходе получаем список сэмплов, по одному для каждого элемента последовательности). А так как нас интересует лишь последний символ, необходимо выбрать только его с помощью индекса `[-1]`.\n",
        "\n",
        "Кроме того, можно ввести параметр (так называемая `температура`), с помощью которого можно управлять выходным распределением и таким образом влиять на непредсказуемость результата. Чем выше температура, тем более случайным будет предсказанный символ. Например, если мы разделим логиты на большое число (температуру), то если бы мы применили софтмакс (для получения вероятностей), то распределение стремилось бы к равномерному (у разных классов уравниваются шансы).\n",
        "\n",
        "Всё, что мы рассмотрели выше, соответствует первой итерации цикла `for`. Далее процесс повторяется, но теперь на входе каждый раз цепочка из одного символа (сгенерированного на предыдущей итерации). И делаем так, пока не соберем выходную цепочку длины `out_len`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZVc4FIxF4_X"
      },
      "source": [
        "def generate_text(model, seed, out_len, temperature=1.0):\n",
        "    text_generated = []\n",
        "\n",
        "    # Обнуляем состояние GRU слоя\n",
        "    for layer in model.layers:\n",
        "        if hasattr(layer, 'reset_states'):\n",
        "            layer.reset_states()\n",
        "\n",
        "    # Конвертируем входную цепочку в индексы\n",
        "    inp = np.array([char2idx[s] for s in seed])\n",
        "\n",
        "    for i in range(out_len):\n",
        "        # Получаем предсказания для входной цепочки inp\n",
        "        # pred - матрица размерности (длина цепочки, распределение по классам)\n",
        "        # На первой итерации цикла длина цепочки равна длине seed, а затем длина равна 1\n",
        "        pred = model(inp[None, ...])[0]\n",
        "\n",
        "        # Применяем температуру к предсказаниям\n",
        "        pred = pred / temperature\n",
        "\n",
        "        # Сэмплируем символ из распределения\n",
        "        pred_c = tf.random.categorical(pred, num_samples=1)[-1][0].numpy()\n",
        "\n",
        "        text_generated.append(idx2char[pred_c])\n",
        "\n",
        "        # Новый вход -- только что сгенерированный символ\n",
        "        inp = np.array([pred_c])\n",
        "\n",
        "    return (seed + ''.join(text_generated))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzdYbeaKq-E5"
      },
      "source": [
        "### Запуск генератора текста\n",
        "\n",
        "Запускаем генерацию текста, передавая на вход желаемое начало цепочки `seed`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAcvNt5VF6Tv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd9d7d82-929e-452c-ae34-65f4558e27b3"
      },
      "source": [
        "print(generate_text(model_inf, seed=u\"MONTAGUE:\", out_len=500))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MONTAGUE:\n",
            "Against him first: he's a very dog to the commonalty.\n",
            "\n",
            "Second Citizen:\n",
            "Consider you what services he has done for his country?\n",
            "\n",
            "First Citizen:\n",
            "Very well; anaccounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCVcKDdSNfGs"
      },
      "source": [
        "**[Задание 1]** Поэксперементируйте с параметром `температура`. Найдите примеры значения параметра, при которых модель ведёт себя предсказуемо (детерминировано) и не предсказуемо (случайно).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Параметр **температура** в генерации текста управляет степенью случайности предсказаний модели. Чем выше температура, тем более случайным будет выход модели, а чем ниже температура, тем более детерминированным и предсказуемым будет результат. Давайте поэкспериментируем с разными значениями температуры и посмотрим, как это влияет на генерацию текста.\n",
        "\n",
        "\n",
        "\n",
        "### **1. Низкая температура (например, 0.1)**\n",
        "При низкой температуре модель становится более уверенной в своих предсказаниях и выбирает наиболее вероятные символы. Это делает текст более предсказуемым и связным, но иногда может приводить к повторениям или зацикливанию.\n",
        "\n"
      ],
      "metadata": {
        "id": "d-09Pf5aqlck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model_inf, seed=u\"MONTAGUE:\", out_len=100, temperature=0.1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziTyZj9BqQNL",
        "outputId": "3fd2f995-e47c-4ae7-f9b1-ba161b17e0d8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MONTAGUE:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **2. Средняя температура (например, 1.0)**\n",
        "При температуре 1.0 модель использует исходное распределение вероятностей, что приводит к балансу между случайностью и предсказуемостью.\n"
      ],
      "metadata": {
        "id": "kD2xzqYSq5J1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model_inf, seed=u\"MONTAGUE:\", out_len=100, temperature=1.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9VFct-qq-b1",
        "outputId": "aad0fcdf-7b15-46d7-9607-8242c544bf24"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MONTAGUE:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **3. Высокая температура (например, 2.0)**\n",
        "При высокой температуре модель становится более случайной, выбирая даже маловероятные символы. Это может привести к бессвязному или абсурдному тексту.\n",
        "\n"
      ],
      "metadata": {
        "id": "6EyP2cNprFXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model_inf, seed=u\"MONTAGUE:\", out_len=100, temperature=2.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOcdMqfBrL2q",
        "outputId": "24c2500c-aa9b-4432-d94f-deb0489d7f98"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MONTAGUE:\n",
            "Resolved. RHSe; for the alved ratinok; $fwe know't.\n",
            "\n",
            "FirstcMluplKTPiut, we know Caius Marciusl?\n",
            "\n",
            "Al\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **4. Очень высокая температура (например, 5.0)**\n",
        "При очень высокой температуре модель становится полностью случайной, и текст теряет всякую связность.\n",
        "\n"
      ],
      "metadata": {
        "id": "DUF7h1bArMHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model_inf, seed=u\"MONTAGUE:\", out_len=100, temperature=5.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wprI0N3IrMjd",
        "outputId": "36d7ab39-5946-4f32-bf18-bd80ac9361f4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MONTAGUE:\n",
            "sw?RRkLe,pe'Bevee:X VDrt'bfyuE?\n",
            "\n",
            "iruF!G\n",
            "bYqH.X!buIXWelFr,w-KtTsy\n",
            "sVJKqSDqTEVerzj\n",
            "hu'Yl!Qwtoqy&\n",
            "OpE!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[Задание 2]** Попробуйте улучшить нейросеть за счёт увеличения её глубины и добавления регуляризации (dropout).\n",
        "\n"
      ],
      "metadata": {
        "id": "Y6StC-WRqQYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Переключаемся на TensorFlow 2.x (если используем Google Colab)\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "# Импорт библиотек\n",
        "import codecs\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "# Загрузка датасета\n",
        "data_fpath = tf.keras.utils.get_file(\n",
        "    'shakespeare.txt',\n",
        "    'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "\n",
        "text = codecs.open(data_fpath, 'r', encoding='utf8').read()\n",
        "print(text[:250])\n",
        "\n",
        "# Создание словаря символов\n",
        "vocab = sorted(set(text))\n",
        "VOCAB_SIZE = len(vocab)\n",
        "\n",
        "print('Vocab: {}'.format(vocab))\n",
        "print('{} unique characters'.format(VOCAB_SIZE))\n",
        "\n",
        "# Создание отображений символов в индексы и обратно\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "# Конвертация текста в последовательность индексов\n",
        "text_as_int = np.array([char2idx[c] for c in text])\n",
        "\n",
        "print('Example of the encoded text: {}'.format(text_as_int[:13]))\n",
        "\n",
        "# Подготовка датасета\n",
        "SEQ_LEN = 1000\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "input_seqs = []\n",
        "target_seqs = []\n",
        "\n",
        "num_seqs = len(text_as_int) // (SEQ_LEN+1)\n",
        "for i in range(num_seqs):\n",
        "    seq = text_as_int[i:i+SEQ_LEN+1]\n",
        "    input_seqs.append(np.array(seq[:-1]))\n",
        "    target_seqs.append(np.array(seq[1:]))\n",
        "\n",
        "input_seqs = np.array(input_seqs)\n",
        "target_seqs = np.array(target_seqs)\n",
        "\n",
        "input_seqs = input_seqs[:(len(input_seqs)//BATCH_SIZE)*BATCH_SIZE]\n",
        "target_seqs = target_seqs[:(len(input_seqs)//BATCH_SIZE)*BATCH_SIZE]\n",
        "\n",
        "print('Input: {} ...'.format([idx2char[i] for i in input_seqs[0][:15]]))\n",
        "print('Target: {} ...'.format([idx2char[i] for i in target_seqs[0][:15]]))\n",
        "\n",
        "# Функция построения модели\n",
        "def build_model(batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        # Embedding слой для отображения индексов символов в векторное представление\n",
        "        tf.keras.layers.Embedding(VOCAB_SIZE, 256, input_length=None),\n",
        "\n",
        "        # Первый GRU слой с Dropout\n",
        "        tf.keras.layers.GRU(512, return_sequences=True, stateful=True),\n",
        "        tf.keras.layers.Dropout(0.2),  # Добавляем Dropout для регуляризации\n",
        "\n",
        "        # Второй GRU слой с Dropout\n",
        "        tf.keras.layers.GRU(512, return_sequences=True, stateful=True),\n",
        "        tf.keras.layers.Dropout(0.2),  # Добавляем Dropout для регуляризации\n",
        "\n",
        "        # Полносвязный слой для предсказания следующего символа\n",
        "        tf.keras.layers.Dense(VOCAB_SIZE),\n",
        "    ])\n",
        "    model.build(input_shape=(batch_size, None))  # Указываем input_shape при вызове build\n",
        "    return model\n",
        "\n",
        "# Создаём модель для обучения\n",
        "model = build_model(BATCH_SIZE)\n",
        "\n",
        "# Компилируем модель\n",
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(optimizer='adam', loss=loss)\n",
        "\n",
        "# Обучаем модель\n",
        "EPOCHS = 20  # Увеличиваем количество эпох для более глубокой модели\n",
        "history = model.fit(input_seqs,\n",
        "                    target_seqs,\n",
        "                    epochs=EPOCHS,\n",
        "                    batch_size=BATCH_SIZE)\n",
        "\n",
        "# Создаём модель для инференса\n",
        "model_inf = build_model(1)\n",
        "\n",
        "# Копируем веса из обученной модели\n",
        "for i in range(len(model_inf.layers)):\n",
        "    for j in range(len(model_inf.layers[i].weights)):\n",
        "        model_inf.layers[i].weights[j].assign(model.layers[i].weights[j])\n",
        "\n",
        "# Функция генерации текста\n",
        "def generate_text(model, seed, out_len, temperature=1.0):\n",
        "    text_generated = []\n",
        "\n",
        "    # Обнуляем состояние GRU слоя\n",
        "    for layer in model.layers:\n",
        "        if hasattr(layer, 'reset_states'):\n",
        "            layer.reset_states()\n",
        "\n",
        "    # Конвертируем входную цепочку в индексы\n",
        "    inp = np.array([char2idx[s] for s in seed])\n",
        "\n",
        "    for i in range(out_len):\n",
        "        # Получаем предсказания для входной цепочки inp\n",
        "        pred = model(inp[None, ...])[0]\n",
        "\n",
        "        # Применяем температуру к предсказаниям\n",
        "        pred = pred / temperature\n",
        "\n",
        "        # Сэмплируем символ из распределения\n",
        "        pred_c = tf.random.categorical(pred, num_samples=1)[-1][0].numpy()\n",
        "\n",
        "        text_generated.append(idx2char[pred_c])\n",
        "\n",
        "        # Новый вход -- только что сгенерированный символ\n",
        "        inp = np.array([pred_c])\n",
        "\n",
        "    return (seed + ''.join(text_generated))\n",
        "\n",
        "# Генерация текста с использованием модифицированной модели\n",
        "print(generate_text(model_inf, seed=u\"MONTAGUE:\", out_len=500, temperature=0.8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHjhCa24qS-d",
        "outputId": "71499e94-6211-470a-a8f6-e1647cbe9b72"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "2.17.1\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "Vocab: ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "65 unique characters\n",
            "Example of the encoded text: [18 47 56 57 58  1 15 47 58 47 64 43 52]\n",
            "Input: ['F', 'i', 'r', 's', 't', ' ', 'C', 'i', 't', 'i', 'z', 'e', 'n', ':', '\\n'] ...\n",
            "Target: ['i', 'r', 's', 't', ' ', 'C', 'i', 't', 'i', 'z', 'e', 'n', ':', '\\n', 'B'] ...\n",
            "Epoch 1/20\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 425ms/step - loss: 3.5821\n",
            "Epoch 2/20\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 428ms/step - loss: 2.4325\n",
            "Epoch 3/20\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 431ms/step - loss: 1.7790\n",
            "Epoch 4/20\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 435ms/step - loss: 1.0645\n",
            "Epoch 5/20\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 439ms/step - loss: 0.3836\n",
            "Epoch 6/20\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 444ms/step - loss: 0.1271\n",
            "Epoch 7/20\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 452ms/step - loss: 0.0661\n",
            "Epoch 8/20\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 455ms/step - loss: 0.0487\n",
            "Epoch 9/20\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 463ms/step - loss: 0.0401\n",
            "Epoch 10/20\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 463ms/step - loss: 0.0360\n",
            "Epoch 11/20\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 462ms/step - loss: 0.0313\n",
            "Epoch 12/20\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 453ms/step - loss: 0.0276\n",
            "Epoch 13/20\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 449ms/step - loss: 0.0249\n",
            "Epoch 14/20\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 449ms/step - loss: 0.0227\n",
            "Epoch 15/20\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 453ms/step - loss: 0.0219\n",
            "Epoch 16/20\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 455ms/step - loss: 0.0212\n",
            "Epoch 17/20\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 454ms/step - loss: 0.0200\n",
            "Epoch 18/20\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 456ms/step - loss: 0.0199\n",
            "Epoch 19/20\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 456ms/step - loss: 0.0188\n",
            "Epoch 20/20\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 453ms/step - loss: 0.0185\n",
            "MONTAGUE:\n",
            "\n",
            "Second Citizen:\n",
            "Nay, but speak not maliciously.\n",
            "\n",
            "First Citizen:\n",
            "I say unto you, what he hath done famously, he did\n",
            "it to that end: though soft-conscienced men can be\n",
            "content to say it was for his country he did it to\n",
            "please his mother and to be partly proud; which he\n",
            "is, even till the altitude of his virtue.\n",
            "\n",
            "Second Citizen:\n",
            "What he cannot help in his nature, you account a\n",
            "vice in him. You must in no way say he is covetous.\n",
            "\n",
            "First Citizen:\n",
            "If I must not, I need not be barren of accusations;\n",
            "he\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**[Задание 3]** Обучите модель Char-RNN на другом корпусе: возьмите датасет IMDB (из предыдущего модуля), объедените все отзывы в один текст и обучитесь на нём.\n",
        "\n"
      ],
      "metadata": {
        "id": "24sVN0VIqTKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Импорт библиотек\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Загрузка датасета IMDB\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
        "\n",
        "# Функция для преобразования последовательностей обратно в текст\n",
        "def decode_review(sequence, word_index):\n",
        "    reverse_word_index = {v: k for k, v in word_index.items()}\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in sequence])\n",
        "\n",
        "# Загрузка словаря слов IMDB\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# Объединение всех отзывов в один текст\n",
        "text = ' '.join([decode_review(review, word_index) for review in x_train + x_test])\n",
        "\n",
        "# Вывод фрагмента текста\n",
        "print(text[:1000])\n",
        "\n",
        "# Создание словаря символов\n",
        "vocab = sorted(set(text))\n",
        "VOCAB_SIZE = len(vocab)\n",
        "\n",
        "print('Vocab: {}'.format(vocab))\n",
        "print('{} unique characters'.format(VOCAB_SIZE))\n",
        "\n",
        "# Создание отображений символов в индексы и обратно\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "# Конвертация текста в последовательность индексов\n",
        "text_as_int = np.array([char2idx[c] for c in text])\n",
        "\n",
        "print('Example of the encoded text: {}'.format(text_as_int[:13]))\n",
        "\n",
        "# Подготовка датасета\n",
        "SEQ_LEN = 1000\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "input_seqs = []\n",
        "target_seqs = []\n",
        "\n",
        "num_seqs = len(text_as_int) // (SEQ_LEN+1)\n",
        "for i in range(num_seqs):\n",
        "    seq = text_as_int[i:i+SEQ_LEN+1]\n",
        "    input_seqs.append(np.array(seq[:-1]))\n",
        "    target_seqs.append(np.array(seq[1:]))\n",
        "\n",
        "input_seqs = np.array(input_seqs)\n",
        "target_seqs = np.array(target_seqs)\n",
        "\n",
        "input_seqs = input_seqs[:(len(input_seqs)//BATCH_SIZE)*BATCH_SIZE]\n",
        "target_seqs = target_seqs[:(len(input_seqs)//BATCH_SIZE)*BATCH_SIZE]\n",
        "\n",
        "print('Input: {} ...'.format([idx2char[i] for i in input_seqs[0][:15]]))\n",
        "print('Target: {} ...'.format([idx2char[i] for i in target_seqs[0][:15]]))\n",
        "\n",
        "# Функция построения модели\n",
        "def build_model(batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        # Embedding слой для отображения индексов символов в векторное представление\n",
        "        tf.keras.layers.Embedding(VOCAB_SIZE, 256, input_length=None),\n",
        "\n",
        "        # Первый GRU слой с Dropout\n",
        "        tf.keras.layers.GRU(512, return_sequences=True, stateful=True),\n",
        "        tf.keras.layers.Dropout(0.2),  # Добавляем Dropout для регуляризации\n",
        "\n",
        "        # Второй GRU слой с Dropout\n",
        "        tf.keras.layers.GRU(512, return_sequences=True, stateful=True),\n",
        "        tf.keras.layers.Dropout(0.2),  # Добавляем Dropout для регуляризации\n",
        "\n",
        "        # Полносвязный слой для предсказания следующего символа\n",
        "        tf.keras.layers.Dense(VOCAB_SIZE),\n",
        "    ])\n",
        "    model.build(input_shape=(batch_size, None))  # Указываем input_shape при вызове build\n",
        "    return model\n",
        "\n",
        "# Создаём модель для обучения\n",
        "model = build_model(BATCH_SIZE)\n",
        "\n",
        "# Компилируем модель\n",
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(optimizer='adam', loss=loss)\n",
        "\n",
        "# Обучаем модель\n",
        "EPOCHS = 20  # Увеличиваем количество эпох для более глубокой модели\n",
        "history = model.fit(input_seqs,\n",
        "                    target_seqs,\n",
        "                    epochs=EPOCHS,\n",
        "                    batch_size=BATCH_SIZE)\n",
        "\n",
        "# Создаём модель для инференса\n",
        "model_inf = build_model(1)\n",
        "\n",
        "# Копируем веса из обученной модели\n",
        "for i in range(len(model_inf.layers)):\n",
        "    for j in range(len(model_inf.layers[i].weights)):\n",
        "        model_inf.layers[i].weights[j].assign(model.layers[i].weights[j])\n",
        "\n",
        "# Функция генерации текста\n",
        "def generate_text(model, seed, out_len, temperature=1.0):\n",
        "    text_generated = []\n",
        "\n",
        "    # Обнуляем состояние GRU слоя\n",
        "    for layer in model.layers:\n",
        "        if hasattr(layer, 'reset_states'):\n",
        "            layer.reset_states()\n",
        "\n",
        "    # Конвертируем входную цепочку в индексы\n",
        "    inp = np.array([char2idx[s] for s in seed])\n",
        "\n",
        "    for i in range(out_len):\n",
        "        # Получаем предсказания для входной цепочки inp\n",
        "        pred = model(inp[None, ...])[0]\n",
        "\n",
        "        # Применяем температуру к предсказаниям\n",
        "        pred = pred / temperature\n",
        "\n",
        "        # Сэмплируем символ из распределения\n",
        "        pred_c = tf.random.categorical(pred, num_samples=1)[-1][0].numpy()\n",
        "\n",
        "        text_generated.append(idx2char[pred_c])\n",
        "\n",
        "        # Новый вход -- только что сгенерированный символ\n",
        "        inp = np.array([pred_c])\n",
        "\n",
        "    return (seed + ''.join(text_generated))\n",
        "\n",
        "# Генерация текста с использованием модифицированной модели\n",
        "print(generate_text(model_inf, seed=u\"I think this movie is\", out_len=500, temperature=0.8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zl5m3A-2qULu",
        "outputId": "eff876d3-81f9-4299-afb5-f0e6b1e88e6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1us/step\n",
            "the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have tw\n",
            "Vocab: [' ', \"'\", '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\x85', '\\x96', '\\x97', '´', 'é', '–']\n",
            "44 unique characters\n",
            "Example of the encoded text: [31 19 16  0 12 30  0 36 26 32  0 34 20]\n",
            "Input: ['t', 'h', 'e', ' ', 'a', 's', ' ', 'y', 'o', 'u', ' ', 'w', 'i', 't', 'h'] ...\n",
            "Target: ['h', 'e', ' ', 'a', 's', ' ', 'y', 'o', 'u', ' ', 'w', 'i', 't', 'h', ' '] ...\n",
            "Epoch 1/20\n",
            "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 454ms/step - loss: 1.4325\n",
            "Epoch 2/20\n",
            "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 454ms/step - loss: 0.0446\n",
            "Epoch 3/20\n",
            "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 455ms/step - loss: 0.0345\n",
            "Epoch 4/20\n",
            "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 455ms/step - loss: 0.0300\n",
            "Epoch 5/20\n",
            "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 454ms/step - loss: 0.0273\n",
            "Epoch 6/20\n",
            "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 455ms/step - loss: 0.0256\n",
            "Epoch 7/20\n",
            "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 455ms/step - loss: 0.0246\n",
            "Epoch 8/20\n",
            "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 455ms/step - loss: 0.0237\n",
            "Epoch 9/20\n",
            "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 455ms/step - loss: 0.0232\n",
            "Epoch 10/20\n",
            "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 455ms/step - loss: 0.0228\n",
            "Epoch 11/20\n",
            "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 455ms/step - loss: 0.0224\n",
            "Epoch 12/20\n",
            "\u001b[1m933/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 455ms/step - loss: 0.0221"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[Задание 4]** Обучите модель синтеза текста на отдельных словах а не на символах. Используйте для этого датасет IMDB с ограниченным словарём `(num_words=...)`.\n"
      ],
      "metadata": {
        "id": "B2ziyO9TqUnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Импорт библиотек\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Загрузка датасета IMDB с ограниченным словарём\n",
        "NUM_WORDS = 1000  # Ограничиваем словарь\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=NUM_WORDS)\n",
        "\n",
        "# Загрузка словаря слов IMDB\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# Создание обратного словаря (индекс -> слово)\n",
        "reverse_word_index = {v: k for k, v in word_index.items()}\n",
        "\n",
        "# Функция для преобразования последовательности индексов в текст\n",
        "def decode_review(sequence):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in sequence])\n",
        "\n",
        "# Объединение всех отзывов в один список слов\n",
        "words = []\n",
        "for review in x_train + x_test:\n",
        "    words.extend(review)\n",
        "\n",
        "# Вывод фрагмента текста\n",
        "print(decode_review(words[:50]))\n",
        "\n",
        "# Создание словаря слов\n",
        "vocab = sorted(set(words))\n",
        "VOCAB_SIZE = len(vocab)\n",
        "\n",
        "print('Vocab size: {}'.format(VOCAB_SIZE))\n",
        "\n",
        "# Создание отображений слов в индексы и обратно\n",
        "word2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2word = np.array(vocab)\n",
        "\n",
        "# Конвертация текста в последовательность индексов\n",
        "words_as_int = np.array([word2idx[word] for word in words])\n",
        "\n",
        "print('Example of the encoded text: {}'.format(words_as_int[:10]))\n",
        "\n",
        "# Подготовка датасета\n",
        "SEQ_LEN = 100  # Длина последовательности слов\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "input_seqs = []\n",
        "target_seqs = []\n",
        "\n",
        "num_seqs = len(words_as_int) // (SEQ_LEN+1)\n",
        "for i in range(num_seqs):\n",
        "    seq = words_as_int[i:i+SEQ_LEN+1]\n",
        "    input_seqs.append(np.array(seq[:-1]))\n",
        "    target_seqs.append(np.array(seq[1:]))\n",
        "\n",
        "input_seqs = np.array(input_seqs)\n",
        "target_seqs = np.array(target_seqs)\n",
        "\n",
        "input_seqs = input_seqs[:(len(input_seqs)//BATCH_SIZE)*BATCH_SIZE]\n",
        "target_seqs = target_seqs[:(len(input_seqs)//BATCH_SIZE)*BATCH_SIZE]\n",
        "\n",
        "print('Input: {} ...'.format([idx2word[i] for i in input_seqs[0][:10]]))\n",
        "print('Target: {} ...'.format([idx2word[i] for i in target_seqs[0][:10]]))\n",
        "\n",
        "# Функция построения модели\n",
        "def build_model(batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        # Embedding слой для отображения индексов слов в векторное представление\n",
        "        tf.keras.layers.Embedding(VOCAB_SIZE, 256, input_length=None),\n",
        "\n",
        "        # Первый GRU слой с Dropout\n",
        "        tf.keras.layers.GRU(512, return_sequences=True, stateful=True),\n",
        "        tf.keras.layers.Dropout(0.2),  # Добавляем Dropout для регуляризации\n",
        "\n",
        "        # Второй GRU слой с Dropout\n",
        "        tf.keras.layers.GRU(512, return_sequences=True, stateful=True),\n",
        "        tf.keras.layers.Dropout(0.2),  # Добавляем Dropout для регуляризации\n",
        "\n",
        "        # Полносвязный слой для предсказания следующего слова\n",
        "        tf.keras.layers.Dense(VOCAB_SIZE),\n",
        "    ])\n",
        "    model.build(input_shape=(batch_size, None))  # Указываем input_shape при вызове build\n",
        "    return model\n",
        "\n",
        "# Создаём модель для обучения\n",
        "model = build_model(BATCH_SIZE)\n",
        "\n",
        "# Компилируем модель\n",
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(optimizer='adam', loss=loss)\n",
        "\n",
        "# Обучаем модель\n",
        "EPOCHS = 10  # Увеличиваем количество эпох для более глубокой модели\n",
        "history = model.fit(input_seqs,\n",
        "                    target_seqs,\n",
        "                    epochs=EPOCHS,\n",
        "                    batch_size=BATCH_SIZE)\n",
        "\n",
        "# Создаём модель для инференса\n",
        "model_inf = build_model(1)\n",
        "\n",
        "# Копируем веса из обученной модели\n",
        "for i in range(len(model_inf.layers)):\n",
        "    for j in range(len(model_inf.layers[i].weights)):\n",
        "        model_inf.layers[i].weights[j].assign(model.layers[i].weights[j])\n",
        "\n",
        "# Функция генерации текста\n",
        "def generate_text(model, seed, out_len, temperature=1.0):\n",
        "    text_generated = []\n",
        "\n",
        "    # Обнуляем состояние GRU слоя\n",
        "    for layer in model.layers:\n",
        "        if hasattr(layer, 'reset_states'):\n",
        "            layer.reset_states()\n",
        "\n",
        "    # Конвертируем входную цепочку в индексы\n",
        "    inp = np.array([word2idx[word] for word in seed.split()])\n",
        "\n",
        "    for i in range(out_len):\n",
        "        # Получаем предсказания для входной цепочки inp\n",
        "        pred = model(inp[None, ...])[0]\n",
        "\n",
        "        # Применяем температуру к предсказаниям\n",
        "        pred = pred / temperature\n",
        "\n",
        "        # Сэмплируем слово из распределения\n",
        "        pred_c = tf.random.categorical(pred, num_samples=1)[-1][0].numpy()\n",
        "\n",
        "        text_generated.append(idx2word[pred_c])\n",
        "\n",
        "        # Новый вход -- только что сгенерированное слово\n",
        "        inp = np.append(inp, pred_c)[-SEQ_LEN:]  # Сохраняем только последние SEQ_LEN слов\n",
        "\n",
        "    return (seed + ' ' + ' '.join(text_generated))\n",
        "\n",
        "# Генерация текста с использованием модифицированной модели\n",
        "print(generate_text(model_inf, seed=\"I think this movie is\", out_len=50, temperature=0.8))"
      ],
      "metadata": {
        "id": "CgeySmp-qVEO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}